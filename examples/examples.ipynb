{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> AWS-foryou </center>\n",
    "### <center> examples </center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Running sklearndiabetes.py as the user's algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "import time\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import awsforyou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diabetes(multiplier=1):\n",
    "    x,y = datasets.load_diabetes(return_X_y=True)\n",
    "    \n",
    "    means = np.mean(x, axis=0)\n",
    "    std = np.std(x)\n",
    "    y_mean = np.mean(y)\n",
    "    y_std = np.std(y)\n",
    "    \n",
    "    n,d = x.shape\n",
    "    \n",
    "    new_x = x\n",
    "    new_y = y\n",
    "    \n",
    "    for i in range(0,multiplier):\n",
    "        mock_x = x + np.random.normal(loc=0, scale=std, size=(n, d))\n",
    "        mock_y = y + np.random.normal(loc=0, scale=y_std, size=(n, 1)).ravel()\n",
    "\n",
    "        new_x = np.append(new_x, mock_x, axis=0)\n",
    "        new_y = np.append(new_y, mock_y, axis=0)\n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_diabetes(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"x_diabetes.csv\", x, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"y_diabetes.csv\", y, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = './x_diabetes.csv'\n",
    "target_loc = './y_diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_diabetes(data_loc, target_loc):\n",
    "    x = np.array(pd.read_csv(data_loc))\n",
    "    y = np.array(pd.read_csv(target_loc))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y.ravel(), random_state=0)\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    linear_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(\"linear regression score = %f\" % linear_score)\n",
    "\n",
    "    # Fit svr model\n",
    "    parameters = \\\n",
    "        {\n",
    "            'gamma':('scale', 'auto'),\n",
    "            'kernel':('linear', 'rbf', 'poly', 'sigmoid'),\n",
    "            'C':[0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 5, 10, 20, 30, 40, 50],\n",
    "            'degree':[3,4,5,6,7,8],\n",
    "        }\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_svr = GridSearchCV(svr, parameters, cv=5, n_jobs=-1, iid=False)\n",
    "    grid_svr.fit(X_train, y_train)\n",
    "\n",
    "    best_estimator = grid_svr.best_estimator_\n",
    "    print(\"best hyperparameters estimate from grid search = \\n %s \" % best_estimator)\n",
    "\n",
    "    best_estimator_score = grid_svr.best_score_\n",
    "    print(\"score from using best hyperparameters = %f\" % best_estimator_score)\n",
    "\n",
    "    print(\"begining 6-components PCA decomposition\")\n",
    "\n",
    "    components = 6\n",
    "    pca = PCA(n_components = components, svd_solver='full')\n",
    "    pca.fit(X_train)\n",
    "    varratio = np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "    print(\"percentage of variance explained = %f\" % varratio)\n",
    "\n",
    "    pca_X_train = pca.transform(X_train)\n",
    "    pca_X_test = pca.transform(X_test)\n",
    "\n",
    "    print(\"repeat grid search with PCA-transformed data\")\n",
    "\n",
    "    # Fit svr model\n",
    "    parameters = \\\n",
    "        {\n",
    "            'gamma':('scale', 'auto'),\n",
    "            'kernel':('linear', 'rbf', 'poly', 'sigmoid'),\n",
    "            'C':[0.0001, 0.001, 0.01, 0.1, 1, 2, 3, 5, 10, 20, 30, 40, 50],\n",
    "            'degree':[3,4,5,6,7,8],\n",
    "        }\n",
    "\n",
    "    svr = SVR()\n",
    "    grid_svr = GridSearchCV(svr, parameters, cv=5, n_jobs=-1, iid=False)\n",
    "    grid_svr.fit(pca_X_train, y_train)\n",
    "\n",
    "    best_estimator = grid_svr.best_estimator_\n",
    "    print(\"best hyperparameters estimate from grid search = \\n %s \" % best_estimator)\n",
    "\n",
    "    best_estimator_score = grid_svr.best_score_\n",
    "    print(\"score from using best hyperparameters = %f\" % best_estimator_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression score = 0.247268\n",
      "best hyperparameters estimate from grid search = \n",
      " SVR(C=20, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "score from using best hyperparameters = 0.237037\n",
      "begining 6-components PCA decomposition\n",
      "percentage of variance explained = 0.780063\n",
      "repeat grid search with PCA-transformed data\n",
      "best hyperparameters estimate from grid search = \n",
      " SVR(C=40, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "score from using best hyperparameters = 0.229473\n",
      "runtime is 107.853706 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sklearn_diabetes(data_loc, target_loc)\n",
    "finish = time.time()\n",
    "runtime = finish - start\n",
    "print(\"runtime is %f seconds\" % runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/winsu/Documents/Seattle/U-of-Washington/Masters-in-Data-Science/2019_Spring/DATA_515/final-project/AWS-foryou/examples'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
